# ğŸ° Disney Reviews RAG System

## The Challenge

This project implements a Retrieval-Augmented Generation (RAG) system to enable semantic search and question-answering over 42,000+ Disneyland reviews from three locations (California, Paris, Hong Kong). The system transforms natural language questions into accurate, source-grounded answers using OpenAI embeddings, FAISS vector search, and GPT-4.

---

## ğŸ“š Documentation

- **[SYSTEM_DESIGN.md](./SYSTEM_DESIGN.md)** 
  - Complete system architecture, RAG flow diagrams, component deep-dive (tiktoken, FAISS, OpenAI), FastAPI server flow, performance metrics, and design trade-offs

- **[QUICKSTART.md](./QUICKSTART.md)** 
  - Step-by-step tutorial to get started quickly, from installation to running your first query

- **[API_README.md](./API_README.md)** - Detailed API documentation with endpoints, request/response schemas, and usage examples

---

## ğŸ”„ RAG Pipeline Architecture

FastAPI orchestrates both the indexing flow (build FAISS index) and query flow (answer user questions):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FASTAPI WEB SERVER                                   â”‚
â”‚                     http://localhost:8000                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          STARTUP (One-time)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ“¦ Application Lifespan (app/main.py)                                      â”‚
â”‚  â”œâ”€ Load configuration from .env                                            â”‚
â”‚  â”œâ”€ Initialize RAGBuilder                                                   â”‚
â”‚  â”‚   â””â”€ Load/Build FAISS index (rag_index/faiss_*.index)                    â”‚
â”‚  â”‚   â””â”€ Load metadata (rag_index/meta_*.jsonl)                              â”‚
â”‚  â”œâ”€ Initialize RAGQueryHandler                                              â”‚
â”‚  â”‚   â””â”€ Ready to handle queries                                             â”‚
â”‚  â”œâ”€ Mount Gradio UI at /ui                                                  â”‚
â”‚  â””â”€ Start server âœ…                                                         â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RUNTIME (Handle Requests)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   INDEXING FLOW (Admin/Setup)    â”‚    â”‚   QUERY FLOW (User Requests)     â”‚
â”‚   Offline / Build Phase          â”‚    â”‚   Online / Production            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        Not exposed via API                      HTTP POST /query
        (Run via notebooks/scripts)              {"query": "...", "k": 5}
                â”‚                                         â”‚
                â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“„ Load Reviews               â”‚      â”‚  ğŸŒ FastAPI Route Handler      â”‚
â”‚  data/DisneylandReviews.csv    â”‚      â”‚  app/api/routes.py             â”‚
â”‚  42,656 reviews                â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
             â”‚                                        â–¼
             â–¼                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  âœ… Validate Request           â”‚
â”‚  âœ‚ï¸ Chunk Text                 â”‚        â”‚  Pydantic: QueryRequest        â”‚
â”‚  RAGBuilder.chunk_texts()      â”‚        â”‚  - query (string)              â”‚
â”‚  tiktoken: 500 tokens/chunk    â”‚        â”‚  - k (1-20, default: 5)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  - temperature (0-2)           â”‚
             â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â–¼
â”‚  ğŸ§® Generate Embeddings        â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAGBuilder                    â”‚      â”‚  ğŸ” RAGQueryHandler.query()    â”‚
â”‚  .get_embeddings_batch()       â”‚      â”‚  app/services/rag_query.py     â”‚
â”‚  OpenAI text-embedding-3       â”‚      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  Step 1: Embed Query           â”‚
             â”‚                          â”‚  â€¢ OpenAI API (~80ms)          â”‚
             â–¼                          â”‚                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚  Step 2: Search FAISS          â”‚
â”‚  ğŸ’¾ Build FAISS Index          â”‚      â”‚  â€¢ index.search(query, k)      â”‚
â”‚  RAGBuilder                    â”‚      â”‚  â€¢ <1ms for 45K vectors        â”‚
â”‚  .build_faiss_index()          â”‚      â”‚                                â”‚
â”‚  IndexFlatL2 (L2 distance)     â”‚      â”‚  Step 3: Retrieve Metadata     â”‚
â”‚  Save: faiss_*.index           â”‚      â”‚  â€¢ Load from meta_*.jsonl      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚                                â”‚
             â”‚                          â”‚  Step 4: Build Prompt          â”‚
             â–¼                          â”‚  â€¢ System + Context + Query    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â”‚
â”‚  ğŸ“ Save Metadata              â”‚      â”‚  Step 5: Generate Answer       â”‚
â”‚  RAGBuilder.save_artifacts()   â”‚      â”‚  â€¢ OpenAI GPT-4o-mini          â”‚
â”‚  Format: JSONL                 â”‚      â”‚  â€¢ Temperature: 0.2            â”‚
â”‚  Save: meta_*.jsonl            â”‚      â”‚  â€¢ (~500ms)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
         âœ… READY FOR QUERIES                        â–¼
         (Index loaded in memory)       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚  ğŸ“Š Record Metrics             â”‚
                                        â”‚  â€¢ Latency: ~600ms             â”‚
                                        â”‚  â€¢ Retrieval quality           â”‚
                                        â”‚  â€¢ Cost: ~$0.0001              â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚  ğŸ“¤ Return Response            â”‚
                                        â”‚  JSON: {                       â”‚
                                        â”‚    "query": "...",             â”‚
                                        â”‚    "answer": "...",            â”‚
                                        â”‚    "retrieval_results": [...]  â”‚
                                        â”‚  }                             â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â–¼
                                              Client receives
                                              answer + sources

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           API ENDPOINTS                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  ğŸ”¹ POST /query         â†’ RAG query with context retrieval + LLM generation â”‚
â”‚  ğŸ”¹ GET  /ui            â†’ Gradio web interface                              â”‚
â”‚  ğŸ”¹ GET  /health        â†’ System health check                               â”‚
â”‚  ğŸ”¹ GET  /metrics       â†’ Performance metrics                               â”‚
â”‚  ğŸ”¹ GET  /docs          â†’ Swagger API documentation                         â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Points:**
- **Indexing Flow**: Run offline via notebooks/scripts to build FAISS index and metadata
- **Query Flow**: FastAPI handles HTTP requests, orchestrates RAG pipeline (retrieve â†’ prompt â†’ generate)
- **FAISS Index**: Loaded into memory at startup for fast <1ms vector search
- **OpenAI API**: Used for embeddings (indexing + queries) and LLM generation (queries only)
- **Total Query Latency**: ~600ms (p50), ~1200ms (p95)

---

## ğŸ“ Project Structure

```
disney_reviews/
â”œâ”€â”€ app/                          # Main application package
â”‚   â”œâ”€â”€ main.py                   # FastAPI application entry point & lifespan
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py             # API endpoints (/query, /ui, /health, /metrics)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ rag_builder.py        # RAG indexing: build/load FAISS indices
â”‚   â”‚   â””â”€â”€ rag_query.py          # RAG retrieval: query processing & LLM
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py            # Pydantic data models for requests/responses
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â””â”€â”€ gradio_interface.py   # Gradio web UI integration
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py             # Configuration & settings management
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ metrics.py            # Metrics collection & statistics
â”‚       â””â”€â”€ logging_config.py     # Structured logging configuration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ DisneylandReviews.csv     # Source dataset (42,656 reviews)
â”œâ”€â”€ rag_index/                    # Persisted vector indices & metadata
â”‚   â”œâ”€â”€ faiss_*.index             # FAISS vector indices (by sample size)
â”‚   â”œâ”€â”€ meta_*.jsonl              # Metadata files (by sample size)
â”‚   â””â”€â”€ embeddings_*.npy          # Cached embeddings (optional)
â”œâ”€â”€ notebooks/                    # Jupyter notebooks for exploration
â”‚   â”œâ”€â”€ analyze_dysney_reviews.ipynb
â”‚   â”œâ”€â”€ rag_flow_query_7.ipynb
â”‚   â””â”€â”€ rag_flow_query_9.ipynb
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ unit/                     # Unit tests (schemas, metrics)
â”‚   â”œâ”€â”€ integration/              # Integration tests (API routes)
â”‚   â””â”€â”€ conftest.py               # Pytest fixtures & configuration
â”œâ”€â”€ logs/                         # Application logs (auto-generated)
â”œâ”€â”€ .env                          # Environment variables (API keys)
â”œâ”€â”€ pyproject.toml                # Project dependencies (uv/pip)
â”œâ”€â”€ requirements.txt              # Pinned dependencies
â””â”€â”€ README.md                     # This file
```


## ğŸ§© Main Classes & Modules

### Core Services

#### `RAGBuilder` (`app/services/rag_builder.py`)
Handles the **indexing phase** of the RAG pipeline:
- **`load_data()`**: Loads review CSV and samples N reviews
- **`chunk_texts()`**: Splits reviews into 500-token chunks with overlap
- **`get_embeddings_batch()`**: Generates embeddings via OpenAI API (with caching)
- **`build_faiss_index()`**: Creates FAISS IndexFlatL2 and saves to disk
- **`build_or_load()`**: Smart loaderâ€”builds if missing, else loads from cache
- **Purpose**: Prepares the searchable knowledge base

#### `RAGQueryHandler` (`app/services/rag_query.py`)
Handles the **retrieval phase** of the RAG pipeline:
- **`retrieve_context()`**: Performs FAISS similarity search for query
- **`build_prompt()`**: Constructs LLM prompt with retrieved context
- **`generate_answer()`**: Calls OpenAI GPT-4 to generate grounded answer
- **`query()`**: Orchestrates full query pipeline (retrieve â†’ prompt â†’ generate)
- **Purpose**: Answers user questions using retrieved context

### API Layer

#### `routes.py` (`app/api/routes.py`)
Defines FastAPI endpoints:
- **`POST /query`**: Main RAG query endpoint (accepts QueryRequest, returns QueryResponse)
- **`GET /ui`**: Gradio web interface for interactive queries
- **`GET /health`**: Health check (returns index status, vector count)
- **`GET /metrics`**: System metrics (throughput, latency, retrieval quality, costs)
- **`GET /`**: Root endpoint (API welcome message)
- **Purpose**: Exposes RAG system via REST API and web UI

#### `main.py` (`app/main.py`)
Application entry point:
- **Lifespan management**: Initializes RAGBuilder and RAGQueryHandler on startup
- **CORS middleware**: Enables cross-origin requests
- **Gradio integration**: Mounts Gradio UI at `/ui`
- **Dependency injection**: Provides query handler to routes
- **Purpose**: Orchestrates application lifecycle

### Data Models

#### `schemas.py` (`app/models/schemas.py`)
Pydantic models for type safety and validation:
- **`QueryRequest`**: User query input (query, k, temperature, model)
- **`RetrievalResult`**: Single search result (rank, distance, branch, rating, snippet)
- **`QueryResponse`**: Complete response (answer + retrieval results + metadata)
- **`HealthResponse`**: Health check response (status, index info)
- **Purpose**: Ensures data consistency and auto-generates API docs

### UI

#### `gradio_interface.py` (`app/ui/gradio_interface.py`)
Web interface for non-technical users:
- **Interactive chat interface**: Text input for queries
- **Parameter controls**: Sliders for k and temperature
- **Results display**: Answer + source citations with metadata
- **Purpose**: Makes RAG system accessible via web UI

### Utilities

#### `metrics.py` (`app/utils/metrics.py`)
Performance tracking:
- **`MetricsCollector`**: Singleton class for collecting metrics
- **Tracks**: Request counts, latency, retrieval distances, model usage, costs
- **Methods**: `record_request()`, `get_stats()`, `get_detailed_stats()`
- **Purpose**: Monitors system health and quality

#### `config.py` (`app/core/config.py`)
Centralized configuration:
- **Settings class**: Pydantic BaseSettings with environment variable loading
- **Parameters**: OpenAI key, data paths, index paths, model settings
- **Defaults**: NUM_SAMPLES=1000, EMBED_MODEL="text-embedding-3-small"
- **Purpose**: Single source of truth for configuration

#### `logging_config.py` (`app/utils/logging_config.py`)
Structured logging:
- **File logging**: Rotating logs in `logs/` directory
- **Console logging**: Colored output for development
- **Log format**: Timestamp, level, module, message
- **Purpose**: Facilitates debugging and monitoring

---

## ğŸ§ª Testing

```bash
# Run all tests with coverage
pytest

# Run specific test categories
pytest -m unit              # Unit tests only
pytest -m integration       # Integration tests only

# Generate coverage report
pytest --cov=app --cov-report=html
open htmlcov/index.html
```

**Test Coverage:**
- **Unit tests** (`tests/unit/`): Schemas, metrics, utilities
- **Integration tests** (`tests/integration/`): API endpoints, RAG flow
- **Fixtures** (`tests/conftest.py`): Mock dependencies for isolated testing

---

## ğŸ“Š Key Metrics

Access at: `http://localhost:8000/metrics`

```json
{
  "metrics": {
    "system": {
      "index_status": "loaded",
      "total_vectors": 45610
    },
    "throughput": {
      "total_requests": 150,
      "successful_requests": 148
    },
    "latency": {
      "average_seconds": 0.623,
      "p50_seconds": 0.580,
      "p95_seconds": 1.234
    },
    "retrieval_quality": {
      "average_distance": 0.387,
      "poor_retrieval_rate": 0.02
    }
  }
}
```

---

## ğŸ› ï¸ Project Configuration

Edit `.env` file to customize:

```bash
# OpenAI API

# Dataset size (pre-built indices available)
NUM_SAMPLES=1000  # Options: 100, 200, 300, 500, 1000, 5000, 10000, 50000, 100000

# Embedding model
EMBED_MODEL=text-embedding-3-small

# LLM model
LLM_MODEL=gpt-4o-mini

# Chunking parameters
MAX_TOKENS=500
OVERLAP=50

# Query defaults
DEFAULT_K=5
DEFAULT_TEMPERATURE=0.2
```
- **[API_README.md](./API_README.md)** - Detailed API documentation with endpoints, request/response schemas, and usage examples

---

## ğŸ¯ Example Queries

```python
# Customer insights
"What do visitors like about Disneyland Paris?"

# Comparative analysis
"How does food quality compare between the three parks?"

# Sentiment analysis
"What are common complaints about Disneyland Hong Kong?"

# Feature discovery
"Which park has the best attractions for young children?"
```

